# 7. 데이터 파이프라인 구축하기
* 데이터 파이프라인아란?
  * 서로 다른 여러 시스템 간의 데이터 이동/흐름
* 카프카 커넥트를 통해 파이프라인에 카프카를 통합하는 작업을 할 수 있다.
* 프로듀서(데이터 생성)와 컨슈머(데이터 소비)를 분리하여 신뢰성 있는 버퍼 역할이 가능

## 데이터 파이프라인 구축시 고려 사항
### 적시성 
* 대량으로 데이터를 받는 배치성 시스템 vs 생성 즉시 전달하는 실시간성 처리 시스템
* 카프카는 실시간 파이프라인부터 시간 단위의 배치 파이프라인까지 모든 것을 지원하는 거대한 버퍼로 사용 될 수 있다.

### 신뢰성
* 장애 발생 시 신속하고 자동화된 복구 필요.
* 또다른 고려 사항은 데이터 전달 보장 : 최소 한 번, 정확히 한 번
* 카프카는 자체적으로 최소 한 번을 보장
* 트랜잭션 처리가 가능한 데이터스토어를 사용하면 정확히 한 번도 가능
* 카프카 커넥트는 외부 시스템과의 데이터 통합에 필요한 api를 제공하여 정확히 한 번을 충족할 수 있음

### 높으면서도 조정 가능한 처리량
* 매우 높은 처리량을 갖도록 확장 가능해야함
* 불시에 처리량이 증가하더라도 조정 가능 해야함

### 데이터 형식
* 데에터 파이프라인에서 중요한 것은 서로 다른 데이터 형식을 조화 시키는 것
* 카프카는 다양한 직렬/역직렬 처리기를 사용해서 우리가 원하는 데이터 형식을 만들어 낼 수 있다.
* 카프카 커넥트 또한 데이터 + 스키마 를 포함하는 객체를 가지고 변환기를 사용해서 데이터 제약에서 벗어 날 수 있다.

### 변환
* 데이터 파이프라인에는 ETL(추출-변환-적재 : Extract-Transform-Load)과 ELT(추출-적재-변환 : Extract-Load-Transform)가 있다
* ETL에 경우 파이프라인을 거쳐가는 데이터를 파이프라인에서 변환할 책임이 있다.
* 전달받은 쪽에서는 스토리지나 시간을 절약할 수 있다.
* row 데이터가 아니라서 끝단 사용자와 애플리케이션의 유연성을 떨어뜨린다.
* 반대로 ELT에 경우 데이터 형변환 정도의 최소한의 변환만 수행
* 대상 시스템은 row 데이터를 전달 받을 수 있음
* cpu와 스토리지에 부담
* 사용자에게 최대한의 유연성을 제공

### 보안
* 파이프라인을 거쳐가는 데이터 암호화
* 파이프라인 수정 권한
* 접근 제어된 시스템에서의 인증 기능
* 카프카 데이터를 싱크(out)로 전달할때 암호화된 데이터의 네트워크 전송을 허용(SASL 인증 지원)
* 카프카는 시스템 접근을 추적관리 하기 위해 감시 로그 제공
* 토픽 데이터 경로 추적 가능

### 장애 처리
* 장애 처리 계획을 만들어야 함
* 카프카는 저장시간을 설정할 수 있어 장애 처리에 유리

### 결합과 민첩성
* 데이터 파이프라인의 가장 중요한 목표는 소스와 타겟을 분리 하는 것
* 애플리케이션을 만들어 데이터 파이프라인을 구축한다면 특정 앤드포인트와 강하게 결합, 유지보수가 힘듬
* 데이터 파이프라인에서 스키마 메타데이터를 보관한다면 버전업이나 변환에 시스템 중단없이 애플리케이션 변화를 줄 수 있다.
* 또한 너무 많은 처리를 해버리면 요구사항 변경에 너무 취약해짐

## 카프카 커넥트 vs 프로듀서/컨슈머
* 카프카를 읽기 위한 외부 시스템 코드를 변경할 수 있을 때 : 카프카 사용
* 변경할 수 없는 외부 시스템(MySql, AWS S3 등등) : 카프카 커넥트
  ![카프카 커넥트](https://cdn.confluent.io/wp-content/uploads/JDBC-connector.png)
## 카프카 커넥트
* 데이터 스토어간 데이터 이동을  위한 확정성과 신뢰성 있는 방법을 제공
* 카프카 커넥트는 여러 개의 작업 프로세스(Worker)들로 실행
  ![Worker](https://docs.confluent.io/platform/current/_images/worker-model-basics.png)

* 커넥터는 데이터를 이동 시키는 방법을 정의하고 task 들을 관리한다.
* 커넥터에는 소스 커넥터와 싱크 커넥터 두 종류가 있음
  ![커넥터](https://docs.confluent.io/platform/current/_images/connector-model.png)

* task 는 실제로 입출력을 담당한다.
  ![task](https://docs.confluent.io/platform/current/_images/data-model-simple.png)

* 이때 task는 컨버터를 사용한다.
  ![컨버터](https://docs.confluent.io/platform/current/_images/converter-basics.png)


* [mode](https://docs.confluent.io/5.1.0/connect/kafka-connect-jdbc/source-connector/source_config_options.html?_ga=2.162856188.1718057337.1637157814-1934929535.1632408811&_gac=1.196341598.1634821938.CjwKCAjwn8SLBhAyEiwAHNTJbbMzEyVW8dx8vZobaT-Vtig9gb8STgUtAL9ORiGnhAaOfaaDUoQ61xoCO_cQAvD_BwE#mode)