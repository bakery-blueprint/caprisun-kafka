# 크로스 클러스터 데이터 미러링
* 하나 이상의 클러스터가 필요할 때가 있음
* 하나의 클러스터를 여러 용도로 사용할 때
* 관리자가 지속적으로 클러스터 간의 데이터를 복사해야 하는 경우
* 같은 클러스터에 속하는 노드 간의 이동/복사는 '복제', 클러스터 간의 데이터 복사는 '미러링'

## 크로스 클러스터 미러링 이용 사례
### 지역과 중앙 클러스터
* 지리적으로 다른 지역에있는 데이터센터에 카프카 클러스터가 있는 경우

### 재해 복구를 위한 이중화
* 비상 상황이 발생했을 때 애플리케이션을 두 번째 클러스터에 연결하여 평상시처럼 작업을 계속 할 수 있다.

### 클라우드 마이그레이션
* 클라우드로 로컬 데이터센터에서 변경된 데이터를 마이그레이션 할 때

## 다중 클러스터 아키텍쳐

### 크로스 데이터센터 통신의 현실적 고려사항

#### 높은 지연성
* 클러스터간 통신 지연은 두 클러스터 간의 거리와 네트워크 홉 개수에 따라 증가한다.

#### 제한된 대역폭
* 원거리 통신망은 데이터 센터 내부 대역폭 보다 낮은 대역폭을 가진다.

#### 더 높은 비용
* 대역폭 추가로 인한 비용 증가

### 허브-스포크 아키텍쳐
* 다수의 데이터 센터에서 중앙 데이터 센터로 데이터를 전송하는 형태
* 데이터가 항상 지역 데이터 센터에서 생성되고 중앙 데이터센터로 미러링 되는 형태
* 장점은 간단한 형태이고 단점은 다른 지역 데이터센터끼리 데이터는 사용할 수가 없음

### 액티브-액티브 아키텍처
* 두 개 이상의 데이터센터가 데이터를 공유하는 형태
* 장점은 데이터의 이중화와 회복력, 장애 대응에 강함
* 단점은 기술적인 어려움으로 인해 데이터의 일관성 유지가 어렵다.
* 데이터센터별 별도의 네임스페이스 접두사를 통해 토픽을 처리할 수 있다.

### 액티브-스탠바이 아키텍처
* 다중 클러스터가 재해 대비만을 위해 필요한 경우
* 장점은 설치가 간단함
* 단점은 실제 완벽한 장애 복구는 실제로 훨씬 어려움

#### 계획에 없던 장애 복구의 데이터 유실과 불일치
* 미러링 솔루션은 대부분 비동기 방식
* 모든 메시지를 DR(재해복구용)클러스터로 옮기지 못할 수 있음

#### 장애 복구 이후 애플리케이션으 시작 오프셋
* 다른 클러스터로 장애 복구를 할 때 가장 어려운 부분은 데이터 읽기를 시작해야 하는 위치를 애플리케이션에서 알 수 있게 하는 것

* **자동 오프셋 재설정**
    * 사용 가능한 데이터의 맨 앞부터 읽기 또는 가장 끝으로 이동하여 데이터 유실을 허용하고 읽을 수 있다.
* **오프셋 토픽을 복제하기**
    * 컨슈머가 자신의 오프셋을 특별한 토픽에 커밋하는 방식, 해당 토픽을 DR 클러스터에서 미러링한다면 오프셋을 선택하여 그 위치부터 읽을 수 있다.
    * 다만 DR 클러스터와 주 클러스터 사이에 오프셋이 일치한다는 보장이 없음
* **시간 기반 장애 복구**
    * 메시지는 카프카에 전송되었던 시간을 나타내는 타임스태프를 가짐
    * 데이터를 읽을 시간을 기준으로 북구
* **외부 오프셋 매핑**
    * 주 클러스터와 DR 클러스터 사이에 오프셋 정보를 외부 데이터베이스에 저장해둠

#### 장애 복구가 끝난 후
* 장애가 생겼던 기존의 주 클러스터를 DR 클러스터로 바꾸고, 복구된 DR 클러스터를 주 클러스토 사용하는 것
* 과거 데이터가 남아 있어서 생길 수 있는 문제가 있으므로, 예전 주 클러스터였던 현 DR 클러스터를 정리할 필요가 있음

#### 클러스터 찾기
* 주 클러스터를 가리키는 DNS를 사용하여, 비상시에는 DNS 이름이 스탠바이 클러스터의 브로커들을 가리킬 수 있게 함


