# 신뢰성 보장
* 신뢰성에서 중요한 것은 보장
* 가장 많이 알려진 신뢰성 보장은 ACID
* 아파치 카프카가 보장하는 것은?
  * 메시지 순서를 보장
  * 각 파티션의 모든 동기화 리플리카에 메시지를 썼다면 해당 메시지는 '커밋'된 것으로 간주
  * 최소한 하나의 리플리카가 살아 있다면 커밋된 메시지는 유실되지 않는다.
  * 컨슈머는 커밋된 메시지만 읽을 수 있다.

# 복제
* 파티션마다 다수의 리플리카를 가질 수 있는 카프카의 복제 메커니즘은 신뢰성 보장의 핵심이다.
* 동기화에 약간 뒤처진 동기화 리플리카는 프로듀서와 컨슈머의 처리 속도를 저할 수 있다.
* 만일 동기화 리플리카의 수가 더 적으면 파티션의 복제가 그만큼 덜 되는 것이므로 중단 시간이나 데이터 유실의 측면에서 위험이 증가한다.

# 브로커 구성
* 카프카는 토픽마다 신뢰성에 관련된 트레이드오프를 제어할 수 있다.

## 복제 팩터
* 토픽 수준에서 복제 팩터를 구성 가능
* 복제 팩터가 N이면 N-1개의 브로커가 중단되더라도 토픽의 데이터를 신뢰성 있게 읽거나 쓸 수 있음
* N개일 경우 N배의 디스크 공간이 필요
* 리플리카의 개수는 토픽의 중요도와 높은 가용성에 따른 지불 가능 비용을 고려해야 한다.
* 예시
  * 복제 팩터가 2면 하나의 브로커가 중단될 경우 불안정한 상태가 됨
  * 그렇기 때문에 가용성이 중요한 토픽은 복제 팩터를 3이상 으로 설정할 것을 권장
* 랙 위치에 따른 설정도 중요

## 언클린 리더 선출
* 이 구성은 브로ㅓ 수준에서 사용할 수 있음
* 파티션 리더가 더이상 사용할 수 없을때 동기화된 리플리카 중 하나가 새로운 리더로 선출 될 때 그 리더를 **클린**리더 선출이라고 한다.
* 사용할 수 없게 된 리더 외에는 동기화된 리플리카들이 아예 없다면 문제가 됨
* 만일 비동기화 리플리카를 새로운 리더가 될 수 없게 설정 한다면, 이전 리더 또는 최근에 동기화된 리플리카가 온라인이 될 때 까지 기다려야 한다.
* 만일 비동기화 리플리카를 새로운 리더가 될 수 있게 설정 한다면, 이전 리더에 썼던 모든 메시지들을 읽게 되고 컨슈머 간에 일관성이 결여 될 수 있다.
* 비동기화 리플리카가 리더가 될 수 있다면 데이터 유실과 일관성 결여의 위험을 감수 해야 함
* 반대로 리더가 될 수 없다면 가용성이 떨어지게 됨

## 최소 동기화 리플리카
* 카프카의 신뢰성 보장에는 모든 동기화 리플리카에 메시지를 썼을 때 커밋된 것으로 간주
* 동기화 리플리카가 없다면 데이터가 유실 될 수 있음
* 동기화된 리플리카 수의 최소값을 설정할 수 있음
* 최소값보다 동기화 리플리카가 적다면 프로듀서는 예외를 받게 되고, 바람직하지 않은 데이터를 읽고 쓰는 것을 방지할 수 있다.

# 프로듀서
* 신뢰성 있게 브로커를 설정하더라도 프로듀서 또한 신뢰성 있게 구성하여야 한다.
* 예시
  * acks 매개변수를 1로 설정하면 리더에만 쓰고 성공적으로 메시지를 썻다고 받게 된다.
  * 그러나 그 메시지를 받은 리더가 복제를 하지 못하고 중단되고, 나머지는 리플리카들은 동기화 상태이므로 메시지를 유실한체 리더가 변경되게 된다.
  * 또한 메시지를 쓸 수 없을 때 재시도를 하지 않게 되면 메시지가 유실될 수 있다.
* 프로듀서는 아래 두가지를 주의 해야 한다. 
  * 신뢰성 요구 사항에 맞도록 acks 구성 설정
  * 구성매개변수와 코드 모두에서 에러 처리를 올바르게 해야 함

## 확인 응답 전송
* acks=0
  * 프로듀서가 네트워크로 메시지를 전송하기만 했다면 성공적으로 쓴 것으로 간주
  * 메시지를 쓸 파티션에 문제가 있더라도 에러를 받지 않기 때문에 메시지 유실 가능성이 큼
  * 실행 속도는 빠름
* acks=1
  * 리더만 메시지를 수신 했다면 응답(정상/에러)을 내려줌
  * 리더가 성공적으로 쓰더라도 리더 중단 시점에 팔로어들에게 복제되지 않았다면 유실 될 수 있음
* acks=all
  * 모든 리플리카 동기화가 완료 되면 리더가 기다리다가 응답(정상/에러)을 내려줌
  * 처리 속도가 느림

## 프로듀서 재시도 구성
* 에러 처리에는 프로듀서가 자동으로 처리하는 에러와 개발자가 프로듀서 라이브러리를 사용해서 처리해야 하는 에러가 있다.
* 프로듀서가 자동으로 처리하는 에러에는 재시도 가능한 에러들이 있음.(ex LEADER_NOT_AVAILABLE)
* 재시도를 해도 동일한 에러는 받는 경우 재시도 불가능한 에러이다.(ex INVALID_CONFIG)
* 다면 **몇번?** 재시도 하도록 구성하는 것은 개발자가 설정해야 한다.
* 또한 메시지 재전송 시도와 에러 처리는 각 메시지가 **최소 한 번** 저장되는 것을 보장하지, **정확히 한 번만** 저장된다는 것은 보장하지 않는다.

## 추가적인 에러 처리
* 메시지 크기, 인증 에러와 같은 재시도 불가능한 브로커 에러
* 브로커에게 전송되기 전 발생하는 에러
* 메모리 에러 등

# 컨슈머
* 컨슈머는 커밋된 메시지만 읽기 때문에 일관성이 보장된 데이터를 읽는다.
* 그렇기 때문에 컨슈머는 읽은 메시지와 읽지 않은 메시지만 잘 파악하면 된다.
* 컨슈머가 중단되고 변경될 경우 시작할 오프셋을 알아야 하기 때문에 오프셋을 **'커밋'**해야 한다.

## 컨슈머 구성 속성
* group id 
  * 컨슈머는 해당 토픽의 일부 파티션을 분담하고 할당받은 파티션의 메시지만 읽게 된다.
* auto.offset.reset
  * 커밋된 오프셋이 없을때 컨슈머가 할 일을 제어하는 변수
  * earliest 로 설정시 파티션의 모든 데이터를 처음부터 읽기 때문에 데이터 누락은 최소화 하지만 중복될 수 있다.
  * latest 로 설정시 파티션의 끝 부터 데이터를 읽기 때문에 데이터 유실이 발생할 수 있다.
* enable.auto.commit
  * 오프셋 커밋을 자동으로 할 껀지 설정할 수 있다.
  * 모든 메시지 처리를 폴링 루프 **안**에서만 한다면 처리한 메시지만 오프셋 커밋하도록 할 수 있다.
  * 다만 자동으로 한다면 중복 메시지를 제어할 수 없다.
* auto.commit.interval.ms
  * 자동 오프셋 커밋하는 시간 간격 조정
  * 시간 설정에 따라 성능 저하가 있지만 컨슈머 중단으로 인한 중복 메시지 수를 줄일 수 있다.

## 컨슈머에서 오프셋 커밋하기
* 오프셋 커밋은 항상 메시지가 처리된 후에 하자.
  * 자동 오프셋 커밋을 사용 하거나, 폴링 루프 끝에서 커밋
* 오프셋 커밋 빈도는 성능과 중복 메시지 개수 간의 트레이드 오프다.
  * 오프셋 커밋은 성능에 영향을 줌
  * 그렇기 때문에 컨슈머 중단으로 인한 중복 메시지 처리와 성능 사이에 비중을 결정해야 한다.
* 어떤 오프셋을 커밋하는지 정확하게 알자
  * 처리가 아닌 읽기를 기준으로 커밋하는 오류가 생길 수 있음
  * 처리된 메시지를 기준으로 커밋
* 리밸런싱
  * 리밸런싱이 실행되기 전에 마지막 처리된 메시지의 오프셋을 커밋하는 드으이 클린업 처리를 해야 한다.(콜백 사용)
* 컨슈머는 상태 데이터를 유지해야 한다.
  * 애플리케이션에 따라 상태 데이터를 유지해야 하는 경우가 있음
  * 이럴때는 누적 상태 값을 특정 토픽에 쓰는 방법이나 카프카 스트림즈 라이브러리르 사용하는 방법이 있다.
* 긴 처리 시간에 대처하기
  * 처리 시간이 오래 걸리는 메시지 처리에 신경을 쓰자.
  * 다만 옛날 버전과 다르게 하트비트 쓰레드가 따로 있어서 크게 문제될건 없을 것 같다.
* Exactl-once 전송
  * 정확히 한번 메시지 처리도 필요하다.
  * 그렇기 때문에 트랜잭션 처리가 가능한 외부 시스템을 활용해 오프셋을 저장한다. 
  * 그리고 저장된 오프셋을 가지고 특정 오프셋 부터 읽기 기능을 활용 할 수 있다.

# 시스템 신뢰성 검사
* 구성 검사
* 애플리케이션 검사
* 모니터링 사용

## 구성 검사
* 우리가 선택한 카프카의 구성이 정상 동작할지 테스트 할 필요가 있다.
* org.apache.kafka.tools 패키지에 구성을 검사할 수 있는 Producer 와 Consumer 이 존재한다.
* 이러한 구성 요소를 가지고 테스트 시나리오를 작성해 구성 검사를 할 수 있다.

## 애플리케이션 검사
* 애플리케이션 또한 다양한 시나리오를 구성해 신뢰성 보장을 해주는지 확인 필요

## 모니터링
* 프로듀서의 경우 레코드당 에러율과 재시도율이 신뢰성 검증에 있어서 가장 중요한 메트릭이다.
* 컨슈머 측면에서는 컨슈머 처리 지연 메트릭이 가장 중요하다.